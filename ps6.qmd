---
title: "Problem Set 6 - Waze Shiny Dashboard"
author: "Claire Conzelmann"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
1. **ps6:** Due Sat 23rd at 5:00PM Central. Worth 100 points (80 points from questions, 10 points for correct submission and 10 points for code style) + 10 extra credit. 

We use (`*`) to indicate a problem that we think might be time consuming. 

# Steps to submit (10 points on PS6) {-}

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*CC\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  \*\*CC\*\* (2 point)
3. Late coins used this pset: \*\*0\*\* Late coins left after submission: \*\*\4\*\*

4. Before starting the problem set, make sure to read and agree to the terms of data usage for the Waze data [here](https://canvas.uchicago.edu/courses/59054/quizzes/130617).

5. Knit your `ps6.qmd` as a pdf document and name it `ps6.pdf`.
6. Submit your `ps6.qmd`, `ps6.pdf`, `requirements.txt`, and all created folders (we will create three Shiny apps so you will have at least three additional folders) to the gradescope repo assignment (5 points).
7. Submit `ps6.pdf` and also link your Github repo via Gradescope (5 points)
8. Tag your submission in Gradescope. For the Code Style part (10 points) please tag the whole correspondingsection for the code style rubric.

*Notes: see the [Quarto documentation (link)](https://quarto.org/docs/authoring/figures.html) for directions on inserting images into your knitted document.*

*IMPORTANT: For the App portion of the PS, in case you can not arrive to the expected functional dashboard we will need to take a look at your `app.py` file. You can use the following code chunk template to "import" and print the content of that file. Please, don't forget to also tag the corresponding code chunk as part of your submission!*

```{python}
#| echo: true
#| eval: false

def print_file_contents(file_path):
    """Print contents of a file."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
            print("```python")
            print(content)
            print("```")
    except FileNotFoundError:
        print("```python")
        print(f"Error: File '{file_path}' not found")
        print("```")
    except Exception as e:
        print("```python") 
        print(f"Error reading file: {e}")
        print("```")

print_file_contents("./top_alerts_map_byhour/app.py") # Change accordingly
```

```{python} 
#| echo: false

# Import required packages.
import altair as alt 
import pandas as pd
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 

import json
```

# Background {-}

## Data Download and Exploration (20 points){-} 

1. 

```{python}
#import waze sample
waze_sample = pd.read_csv("Data/waze_data/waze_data_sample.csv", index_col=[0])
```

```{python}
#print variable names and type
waze_sample.dtypes
```

Using the python data types and browsing the data, the variables are the following type:
|   Variable   | Data type        |
|:------------:|------------------|
| city         | nominal          |
| confidence   | ordinal          |
| nThumbsUp    | quantitative     |
| street       | nominal          |
| uuid         | nominal, ordinal |
| country      | nominal          |
| type         | nominal          |
| subtype      | nominal          |
| roadType     | ordinal          |
| reliability  | ordinal          |
| magvar       | quantitative     |
| reportRating | ordinal          |

It's not clear if uuid is assigned in any particular order, so it is likely nominal, though if you could use it to determine the order in which it was assigned, it would be ordinal. It's also not clear if type and subtype have an inherent order to them (i.e. is jam worse than hazard?). Because of this, type and subtype are likely nominal, though if there was some kind of key to determine which is worse, it would be ordinal.

2. 

```{python}
#load full data
waze_df = pd.read_csv("Data/waze_data/waze_data.csv")
```

```{python}
# Count the number of NA values in each variable
def count_nas(df):
  #generate df that has counts of nas for each column in a dataframe
  nas = df.isna().sum(axis=0).reset_index()

  #rename columns
  nas = nas.rename(columns={"index":"variable_name", 0:"n_nas"})

  #generate number of non missings
  nas["n_non_nas"] = len(waze_df) - nas["n_nas"] 

  return nas

#apply function to tickets df and report the results
count_nas_df = count_nas(waze_df)
count_nas_df
```

```{python}
#reshape data to long
count_nas_long = count_nas_df.melt(id_vars="variable_name", 
                      value_vars=["n_nas", "n_non_nas"], 
                      var_name="status", 
                      value_name="count")

#create stacked bar chart
alt.Chart(count_nas_long).mark_bar().encode(
    x=alt.X("variable_name", title="Variable"),
    y=alt.Y("count", title="Count"),
    color=alt.Color("status", scale=alt.Scale(domain=["n_nas", "n_non_nas"]))
).properties(
    title="Missing vs Non-Missing Counts by Variable")
```

The variables nThumbsUp, subtype, and street all have missing values. nThumbsUp has the largest share of missing values, with almost all of its values being missing.

3. 

```{python}
#print unique values in each variable
print(waze_df["type"].unique())
print(waze_df["subtype"].unique())

#print unique combinations of type and subtype
unique_combinations = waze_df[["type", "subtype"]].drop_duplicates(
  ).sort_values("type")
print(unique_combinations[["type", "subtype"]])
```

All types have a subtype that is NA. I think we should keep the NA values and recode them to "unclassified" because these unclassified observations could still hold valuable information in other variables in our dataset. Dropping them would prevent us from using these observations in any other analysis with variables other than subtype. Also, perhaps there is a pattern with what observations are unclassified that we would be missing by removing them from the dataset. 

- Accident
  - Major
  - Minor
  - Unclassified

- Hazard
  - Weather
    - Heavy snow
    - Fog
    - Flood
    - Hail
  - On shoulder
    - Car stopped
    - Missing sign
    - Animals
  - On road
    - Road kill
    - Lane closed
    - Pot hole
    - Car stopped
    - Construction
    - Traffic light fault
    - Emergency vehicle
    - Ice
    - Object
  - Unclassified

- Jam
  - Light
  - Moderate
  - Heavy
  - Stand still 
  - Unclassified

- Road closed
  - Event
  - Construction 
  - Hazard
  - Unclassified

4. 

1. 
```{python}
#create crosswalk dataframe 
xwalk = unique_combinations[["type", "subtype"]]

#create new type variable
xwalk["updated_type"] = xwalk["type"]

#create new subtype variable
xwalk["updated_subtype"] = xwalk["subtype"]

#create new subtype variable
xwalk["updated_subsubtype"] = xwalk["subtype"]
```

2. 

```{python}
#create dictionaries to replace values
type_xwalk = {"ACCIDENT":"Accident", 
              "HAZARD":"Hazard", 
              "ROAD_CLOSED":"Road Closed", 
              "JAM": "Jam"}
subtype_xwalk = {"ACCIDENT_MAJOR":"Major", "ACCIDENT_MINOR":"Minor",
                  "HAZARD_ON_SHOULDER_CAR_STOPPED":"On Shoulder", "HAZARD_WEATHER_HEAVY_SNOW":"Weather", "HAZARD_ON_SHOULDER_MISSING_SIGN":"On Shoulder", "HAZARD_ON_SHOULDER_ANIMALS":"On Shoulder", "HAZARD_ON_ROAD_ANIMALS":"On Road", "HAZARD_ON_ROAD_ROAD_KILL":"On Road", "HAZARD_WEATHER_FOG":"Weather",
                  "HAZARD_WEATHER_HEAVY_SNOW":"Weather", "HAZARD_ON_ROAD_LANE_CLOSED":"On Road", "HAZARD_WEATHER_FLOOD":"Weather", "HAZARD_WEATHER":"Weather", "HAZARD_ON_SHOULDER":"On Shoulder", "HAZARD_WEATHER_HAIL":"Weather", "HAZARD_ON_ROAD_POT_HOLE":"On Road", "HAZARD_ON_ROAD":"On Road", "HAZARD_ON_ROAD_CAR_STOPPED":"On Road", "HAZARD_ON_ROAD_CONSTRUCTION":"On Road", "HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT":"On Road", "HAZARD_ON_ROAD_EMERGENCY_VEHICLE":"On Road", "HAZARD_ON_ROAD_ICE":"On Road", "HAZARD_ON_ROAD_OBJECT":"On Road", "JAM_MODERATE_TRAFFIC":"Moderate", "JAM_HEAVY_TRAFFIC":"Heavy", "JAM_LIGHT_TRAFFIC":"Light", "JAM_STAND_STILL_TRAFFIC":"Stand Still", "ROAD_CLOSED_EVENT":"Event", "ROAD_CLOSED_CONSTRUCTION":"Construction", "ROAD_CLOSED_HAZARD":"Hazard", np.nan:"Unclassified"}

subsubtype_xwalk = {"ACCIDENT_MAJOR":np.nan, "ACCIDENT_MINOR":np.nan,
                    "HAZARD_ON_SHOULDER_CAR_STOPPED":"Car Stopped", "HAZARD_WEATHER_HEAVY_SNOW":"Snow", "HAZARD_ON_SHOULDER_MISSING_SIGN":"Missing Sign", "HAZARD_ON_SHOULDER_ANIMALS":"Animals", "HAZARD_ON_ROAD_ANIMALS":"Animals", "HAZARD_ON_ROAD_ROAD_KILL":"Road Kill", "HAZARD_WEATHER_FOG":"Fog", "HAZARD_ON_ROAD_LANE_CLOSED":"Lane Closed", "HAZARD_WEATHER_FLOOD":"Flood", "HAZARD_WEATHER":np.nan, "HAZARD_ON_SHOULDER":np.nan, "HAZARD_WEATHER_HAIL":"Hail", "HAZARD_ON_ROAD_POT_HOLE":"Pot Hole", "HAZARD_ON_ROAD":np.nan, "HAZARD_ON_ROAD_CAR_STOPPED":"Car Stopped", "HAZARD_ON_ROAD_CONSTRUCTION":"Construction", "HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT":"Traffic Light Fault", "HAZARD_ON_ROAD_EMERGENCY_VEHICLE":"Emergency Vehicle", "HAZARD_ON_ROAD_ICE":"Ice", "HAZARD_ON_ROAD_OBJECT":"Object", "JAM_MODERATE_TRAFFIC":np.nan, "JAM_HEAVY_TRAFFIC":np.nan, "JAM_LIGHT_TRAFFIC":np.nan, "JAM_STAND_STILL_TRAFFIC":np.nan, "ROAD_CLOSED_EVENT":np.nan, "ROAD_CLOSED_CONSTRUCTION":np.nan, "ROAD_CLOSED_HAZARD":np.nan}

#replace new type variable
xwalk["updated_type"] = xwalk["type"].replace(type_xwalk)

#replace new subtype variable
xwalk["updated_subtype"] = xwalk["subtype"].replace(subtype_xwalk)

#replace new subtype variable
xwalk["updated_subsubtype"] = xwalk["subtype"].replace(subsubtype_xwalk)            
```

3. 

```{python}
#merge in new types and subtypes
waze_df = pd.merge(waze_df, xwalk, on=["type", "subtype"], how="left")
sum((waze_df["updated_type"]=="Accident") & (waze_df["updated_subtype"]=="Unclassified"))
```

There are 24,359 rows with accident-unclassified.

4. Extra credit/optional

```{python}

```


# App #1: Top Location by Alert Type Dashboard (30 points){-}

1. 

a. 
```{python}

```

b. 
```{python}

```


c. 
```{python}

```

d. 
```{python}

```

3. 
    
a. 

```{python}

```
    

b. 
```{python}
# MODIFY ACCORDINGLY
file_path = "./top_alerts_map/chicago-boundaries.geojson"
#----

with open(file_path) as f:
    chicago_geojson = json.load(f)

geo_data = alt.Data(values=chicago_geojson["features"])

```

4. 

```{python}

```

5. 

a. 

```{python}

```

b. 
```{python}

```

c. 
```{python}

```

d. 
```{python}

```

e. 

# App #2: Top Location by Alert Type and Hour Dashboard (20 points) {-}

1. 

a. 


    
b. 
```{python}

```

c.

```{python}

```
    

2.

a. 



b. 


c. 


# App #3: Top Location by Alert Type and Hour Dashboard (20 points){-}

1. 


a. 

b. 

```{python}

```

2. 

a. 


b. 
    
3. 

a. 
    

b. 


c. 


d.
